{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one-off preparation and download of the database (optional)\n",
    "\n",
    "It is recommended to work on a local lamin database in many instances:\n",
    "\n",
    "1. you might want to do some dataset level preprocessing (PCA, neighboors, clustering, re-annotation, harmonization of labels, etc..) \n",
    "2. to make the loading time much faster when you do large training runs\n",
    "3. to work on compute nodes that might not have access to internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-13 16:40:32,919:INFO - HTTP Request: GET https://hub.lamin.ai/rest/v1/instance?select=%2A%2C%20account%21inner%21fk_instance_account_id_account%28%2A%29&account.handle=eq.jkobject&name=eq.scprint \"HTTP/1.1 401 Unauthorized\"\n",
      "2023-12-13 16:40:33,431:INFO - HTTP Request: POST https://hub.lamin.ai/auth/v1/token?grant_type=password \"HTTP/1.1 200 OK\"\n",
      "2023-12-13 16:40:33,745:INFO - HTTP Request: POST https://hub.lamin.ai/auth/v1/logout \"HTTP/1.1 204 No Content\"\n",
      "2023-12-13 16:40:34,089:INFO - HTTP Request: GET https://hub.lamin.ai/rest/v1/instance?select=%2A%2C%20account%21inner%21fk_instance_account_id_account%28%2A%29&account.handle=eq.jkobject&name=eq.scprint \"HTTP/1.1 200 OK\"\n",
      "2023-12-13 16:40:34,367:INFO - HTTP Request: GET https://hub.lamin.ai/rest/v1/account?select=%2A&handle=eq.jkobject \"HTTP/1.1 200 OK\"\n",
      "2023-12-13 16:40:34,487:INFO - HTTP Request: GET https://hub.lamin.ai/rest/v1/instance?select=%2A&account_id=eq.8292b4ae-8139-4cff-ade2-fd6447734471&name=eq.scprint \"HTTP/1.1 200 OK\"\n",
      "üí° found cached instance metadata: /home/ml4ig1/.lamin/instance--jkobject--scprint.env\n",
      "üí° loaded instance: jkobject/scprint\n",
      "2023-12-13 16:40:33,431:INFO - HTTP Request: POST https://hub.lamin.ai/auth/v1/token?grant_type=password \"HTTP/1.1 200 OK\"\n",
      "2023-12-13 16:40:33,745:INFO - HTTP Request: POST https://hub.lamin.ai/auth/v1/logout \"HTTP/1.1 204 No Content\"\n",
      "2023-12-13 16:40:34,089:INFO - HTTP Request: GET https://hub.lamin.ai/rest/v1/instance?select=%2A%2C%20account%21inner%21fk_instance_account_id_account%28%2A%29&account.handle=eq.jkobject&name=eq.scprint \"HTTP/1.1 200 OK\"\n",
      "2023-12-13 16:40:34,367:INFO - HTTP Request: GET https://hub.lamin.ai/rest/v1/account?select=%2A&handle=eq.jkobject \"HTTP/1.1 200 OK\"\n",
      "2023-12-13 16:40:34,487:INFO - HTTP Request: GET https://hub.lamin.ai/rest/v1/instance?select=%2A&account_id=eq.8292b4ae-8139-4cff-ade2-fd6447734471&name=eq.scprint \"HTTP/1.1 200 OK\"\n",
      "üí° found cached instance metadata: /home/ml4ig1/.lamin/instance--jkobject--scprint.env\n",
      "üí° loaded instance: jkobject/scprint\n"
     ]
    }
   ],
   "source": [
    "# initialize a local lamin database\n",
    "!lamin init --storage ~/scdataloader --schema bionty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° lamindb instance: jkobject/scprint\n"
     ]
    }
   ],
   "source": [
    "from scdataloader import utils\n",
    "\n",
    "import lamindb as ln\n",
    "import lnschema_bionty as lb\n",
    "import pandas as pd\n",
    "\n",
    "lb.settings.organism = \"human\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load some known ontology names\n",
    "\n",
    "first if you use a local instance you will need to populate your ontologies. \n",
    "\n",
    "one could just add everything by keeping the default `None` value for the `ontology` argument, but this will take a long time.\n",
    "\n",
    "Instead, we will load only the ontologies we need. By using all the used/existing cellxgene ontology names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can also load it back\n",
    "mydataset = ln.Dataset.filter(name=\"cellxgene-local\").one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39055600, 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cellxgene_census\n",
    "\n",
    "census = cellxgene_census.open_soma(census_version = \"latest\")\n",
    "val_to_get = ['self_reported_ethnicity_ontology_term_id', 'assay_ontology_term_id', 'development_stage_ontology_term_id', 'disease_ontology_term_id', 'tissue_ontology_term_id']\n",
    "df = census[\"census_data\"][\"homo_sapiens\"].obs.read(column_names=val_to_get, value_filter=\"is_primary_data == True\").concat().to_pandas()\n",
    "df2 = census[\"census_data\"][\"mus_musculus\"].obs.read(column_names=val_to_get, value_filter=\"is_primary_data == True\").concat().to_pandas()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùó now recursing through parents: this only happens once, but is much slower than bulk saving\n",
      "‚ùó now recursing through parents: this only happens once, but is much slower than bulk saving\n"
     ]
    }
   ],
   "source": [
    "utils.populate_my_ontology(lb=lb,\n",
    "    organisms=[\"NCBITaxon:10090\", \"NCBITaxon:9606\"],\n",
    "    sex=[\"PATO:0000384\", \"PATO:0000383\"],\n",
    "    ethnicities=df['self_reported_ethnicity_ontology_term_id'].unique().tolist(),\n",
    "    assays=list(set(df['assay_ontology_term_id'].unique()).union(df2['assay_ontology_term_id'].unique())) + ['EFO:0010961'],\n",
    "    tissues=list(set(df['tissue_ontology_term_id'].unique()).union(df2['tissue_ontology_term_id'].unique())),\n",
    "    # we load all possible diseases. makes it easier\n",
    "    #diseases=list(set(df['disease_ontology_term_id'].unique()).union(df2['disease_ontology_term_id'].unique())),\n",
    "    dev_stages=list(df['development_stage_ontology_term_id'].unique()),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL: add some missing ontology names\n",
    "\n",
    "in some instances you would have to add missing ontologies in the case where you haven't loaded everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_tissues = {\n",
    "    \"UBERON:0037144\": \"wall of heart\",\n",
    "    \"UBERON:0003929\": \"digestive tract epithelium\",\n",
    "    \"UBERON:0002020\": \"gray matter\",\n",
    "    \"UBERON:0000200\": \"gyrus\",\n",
    "    \"UBERON:0000101\": \"lobe of lung\",\n",
    "    \"UBERON:0001981\": \"blood vessel\",\n",
    "    \"UBERON:0001474\": \"bone element\",\n",
    "}\n",
    "\n",
    "additional_diseases = {\n",
    "    \"MONDO:0001106\": \"kidney failure\",\n",
    "    \"MONDO:0021166\": \"inflammatory disease\",\n",
    "    \"MONDO:0004992\": \"cancer\",\n",
    "    \"MONDO:0004994\": \"cardiomyopathy\",\n",
    "    \"MONDO:0700065\": \"trisomy\",\n",
    "    \"MONDO:0021042\": \"glioma\",\n",
    "    \"MONDO:0005265\": \"inflammatory bowel disease\",\n",
    "    \"MONDO:0005550\": \"infectious disease\",\n",
    "    \"MONDO:0005059\": \"leukemia\",\n",
    "}\n",
    "\n",
    "additional_assays = {\n",
    "    \"EFO:0010184\": \"Smart-like\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Did it using the code below to figure out things we might want to add etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping, anc, leafs = utils.get_ancestry_mapping(df['tissue_ontology_term_id'].unique(), lb.Tissue.filter().df(include=[\"parents__ontology_id\"]).set_index(\"ontology_id\"))\n",
    "# getting only the leaves for which we don't have a parent\n",
    "leafs = list(leafs - set.union(*[mapping[val] for val in mapping.keys()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb.Tissue.search(list(leafs)[108], field=\"ontology_id\",return_queryset=True).first().view_parents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùó now recursing through parents: this only happens once, but is much slower than bulk saving\n"
     ]
    }
   ],
   "source": [
    "bionty_source_ds_mouse = lb.BiontySource.filter(entity=\"DevelopmentalStage\", organism=\"mouse\").one()\n",
    "records = lb.DevelopmentalStage.from_values(df2['development_stage_ontology_term_id'].unique().tolist(), field=lb.DevelopmentalStage.ontology_id, bionty_source=bionty_source_ds_mouse)\n",
    "ln.save(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùó now recursing through parents: this only happens once, but is much slower than bulk saving\n"
     ]
    }
   ],
   "source": [
    "assay = ['EFO:0010961']\n",
    "records = lb.ExperimentalFactor.from_values(assay, field=lb.ExperimentalFactor.ontology_id)\n",
    "ln.save(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directly download a lamin database\n",
    "\n",
    "In this context one ca either directly download a lamin database (here the cellxgene database as example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx_dataset = ln.Dataset.using(\"laminlabs/cellxgene\").one()\n",
    "cx_dataset, len(cx_dataset.files.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùó record with EtxwAoHUyGTdCB8swqaf already exists on default database: File(uid='EtxwAoHUyGTdCB8swqaf', key='cell-census/2023-07-25/h5ads/0738f538-ff2f-4346-b2eb-72704c291188.h5ad', suffix='.h5ad', accessor='AnnData', description='High Resolution Slide-seqV2 Spatial Transcriptomics Enables Discovery of Disease-Specific Cell Neighborhoods and Pathways', size=12110480, hash='8PORLeHJm9wYZ5MUc4AlSw-2', hash_type='md5-n', visibility=1, key_is_virtual=False, updated_at=2023-11-28 22:44:40 UTC, storage_id=2, transform_id=11, run_id=16, created_by_id=1)\n",
      "File cell-census/2023-07-25/h5ads/0738f538-ff2f-4346-b2eb-72704c291188.h5ad already exists in storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n",
      "File cell-census/2023-07-25/h5ads/07428d73-fdea-4bd4-a801-94b00c4d961c.h5ad already exists in storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/asyncio/sslproto.py:320: ResourceWarning: unclosed transport <asyncio.sslproto._SSLProtocolTransport object at 0x7f8b49dda980>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cell-census/2023-07-25/h5ads/07854d9c-5375-4a9b-ac34-fa919d3c3686.h5ad already exists in storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/asyncio/sslproto.py:320: ResourceWarning: unclosed transport <asyncio.sslproto._SSLProtocolTransport object at 0x7f8b450b9420>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cell-census/2023-07-25/h5ads/07b1d7c8-5c2e-42f7-9246-26f746cd6013.h5ad already exists in storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/asyncio/sslproto.py:320: ResourceWarning: unclosed transport <asyncio.sslproto._SSLProtocolTransport object at 0x7f8b49b798a0>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cell-census/2023-07-25/h5ads/08e94873-c2a6-4f7d-ab72-aeaff3e3f929.h5ad already exists in storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/asyncio/sslproto.py:320: ResourceWarning: unclosed transport <asyncio.sslproto._SSLProtocolTransport object at 0x7f8b4514e200>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cell-census/2023-07-25/h5ads/090da8ea-46e8-40df-bffc-1f78e1538d27.h5ad already exists in storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/asyncio/sslproto.py:320: ResourceWarning: unclosed transport <asyncio.sslproto._SSLProtocolTransport object at 0x7f8b47684b80>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cell-census/2023-07-25/h5ads/095940cb-7422-4510-96e2-cbafd961eb88.h5ad already exists in storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/asyncio/sslproto.py:320: ResourceWarning: unclosed transport <asyncio.sslproto._SSLProtocolTransport object at 0x7f8b44f692a0>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cell-census/2023-07-25/h5ads/0a21f80c-e7a3-465b-8aba-fdda2b4c36bc.h5ad already exists in storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/asyncio/sslproto.py:320: ResourceWarning: unclosed transport <asyncio.sslproto._SSLProtocolTransport object at 0x7f8b491f8ee0>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cell-census/2023-07-25/h5ads/0ae96eac-ff08-4870-9bc3-cd12418af7e4.h5ad already exists in storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/asyncio/sslproto.py:320: ResourceWarning: unclosed transport <asyncio.sslproto._SSLProtocolTransport object at 0x7f8b450bb0a0>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cell-census/2023-07-25/h5ads/0b4a15a7-4e9e-4555-9733-2423e5c66469.h5ad already exists in storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/asyncio/sslproto.py:320: ResourceWarning: unclosed transport <asyncio.sslproto._SSLProtocolTransport object at 0x7f8b49b7a0e0>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cell-census/2023-07-25/h5ads/0b75c598-0893-4216-afe8-5414cab7739d.h5ad already exists in storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/asyncio/sslproto.py:320: ResourceWarning: unclosed transport <asyncio.sslproto._SSLProtocolTransport object at 0x7f8b49dda980>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cell-census/2023-07-25/h5ads/0ba636a1-4754-4786-a8be-7ab3cf760fd6.h5ad already exists in storage\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mydataset = utils.load_dataset_local(lb, cx_dataset, \"~/scdataloader/\", name=\"cellxgene-local\", description=\"the full cellxgene database\", only=(21,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or Preprocessing + Download\n",
    "\n",
    "In this case we use a custom made function that applies a preprocessing after downloading each files in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scdataloader.preprocess import Preprocessor\n",
    "import scanpy as sc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESCRIPTION='preprocessed by scprint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we also add some additional preprocessing (happens at the beginning of the preprocessing function) and post processing (happens at the end of the preprocessing function)\n",
    "# this serves as an exemple of the flexibility of the function\n",
    "\n",
    "def additional_preprocess(adata):\n",
    "    adata.obs = adata.obs.replace({'self_reported_ethnicity_ontology_term_id':{\n",
    "        'multiethnic':'unknown',\n",
    "        'American':'unknown',\n",
    "        'Jewish Israeli': 'unknown',\n",
    "        'na':'unknown',\n",
    "    }}) #multi ethnic will have to get renamed\n",
    "    adata.obs['cell_culture'] = False\n",
    "    # if cell_type contains the word \"(cell culture)\" then it is a cell culture and we mark it as so and remove this from the cell type\n",
    "    loc = adata.obs['cell_type_ontology_term_id'].str.contains(\"(cell culture)\")\n",
    "    if loc.sum()>0:\n",
    "        adata.obs.loc[loc, 'cell_culture'] = True\n",
    "        adata.obs.loc[loc, 'cell_type_ontology_term_id'] = adata.obs.loc[loc, 'cell_type_ontology_term_id'].str.replace(\" (cell culture)\", \"\")\n",
    "    return adata\n",
    "\n",
    "def additional_postprocess(adata):\n",
    "    # define the \"up to\" 10 neighbors for each cells and add to obs\n",
    "    # compute neighbors\n",
    "    # need to be connectivities and same labels [cell type, assay, dataset, disease]\n",
    "    # define the \"neighbor\" up to 10(N) cells and add to obs\n",
    "    # define the \"next time point\" up to 5(M) cells and add to obs  # step 1: filter genes\n",
    "    sc.tl.diffmap(adata)\n",
    "    # create a meta group\n",
    "    adata.obs['dpt_group'] = adata.obs['leiden_1'].astype(str) + \"_\" + adata.obs['disease_ontology_term_id'].astype(str) + \"_\" + adata.obs['cell_type_ontology_term_id'].astype(str) + \"_\" + adata.obs['tissue_ontology_term_id'].astype(str) #+ \"_\" + adata.obs['dataset_id'].astype(str)\n",
    "\n",
    "    # if group is too small\n",
    "    okgroup = [i for i, j in adata.obs['dpt_group'].value_counts().items() if j>=10]\n",
    "    not_okgroup = [i for i, j in adata.obs['dpt_group'].value_counts().items() if j<3]\n",
    "    # set the group to empty\n",
    "    adata.obs.loc[adata.obs['dpt_group'].isin(not_okgroup), 'dpt_group'] = ''\n",
    "    adata.obs['heat_diff'] = np.nan\n",
    "    # for each group\n",
    "    for val in set(okgroup):\n",
    "        if val == '':\n",
    "            continue\n",
    "        # get the best root cell\n",
    "        eq = adata.obs.dpt_group==val\n",
    "        loc = np.where(eq)[0]\n",
    "\n",
    "        root_ixs = loc[adata.obsm[\"X_diffmap\"][eq, 0].argmin()]\n",
    "        adata.uns[\"iroot\"] = root_ixs\n",
    "        # compute the diffusion pseudo time from it\n",
    "        sc.tl.dpt(adata)\n",
    "        adata.obs.loc[eq, 'heat_diff'] = adata.obs.loc[eq, 'dpt_pseudotime']\n",
    "        adata.obs.drop(columns=['dpt_pseudotime'], inplace=True)\n",
    "\n",
    "    #sort so that the next time points are aligned for all groups\n",
    "    adata = adata[adata.obs.sort_values(['dpt_group','heat_diff']).index]\n",
    "    #to query N next time points we just get the N elements below and check they are in the group\n",
    "    # to query the N nearest neighbors we just get the N elements above and N below and check they are in the group\n",
    "    return adata\n",
    "\n",
    "do_preprocess = Preprocessor(lb, additional_postprocess=additional_postprocess, additional_preprocess=additional_preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs √ó n_vars = 69709 √ó 25701\n",
      "    obs: 'n_genes', 'sample', 'percent_mito', 'n_counts', 'batch', 'S_score', 'G2M_score', 'phase', 'scrublet_score', 'scrublet_cluster_score', 'zscore', 'bh_pval', 'bonf_pval', 'is_doublet', 'lineage', 'dataset', 'lineageSomatic', 'assay_ontology_term_id', 'cell_type_ontology_term_id', 'development_stage_ontology_term_id', 'disease_ontology_term_id', 'donor_id', 'is_primary_data', 'organism_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'sex_ontology_term_id', 'suspension_type', 'tissue_ontology_term_id', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage'\n",
      "    var: 'gene_symbols', 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype'\n",
      "    uns: 'default_embedding', 'lineageSomatic_colors', 'lineage_colors', 'schema_version', 'title'\n",
      "    obsm: 'X_scVI', 'X_umap'\n",
      "Removed 49 genes.\n",
      "Seeing 31596 outliers (45.33% of total dataset):\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'dpt_group' as categorical\n",
      "... storing 'gene_symbols' as categorical\n",
      "... storing 'symbol' as categorical\n",
      "... storing 'ncbi_gene_id' as categorical\n",
      "... storing 'biotype' as categorical\n",
      "... storing 'description' as categorical\n",
      "... storing 'synonyms' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "AnnData object with n_obs √ó n_vars = 13623 √ó 59357\n",
      "    obs: 'roi', 'organism_ontology_term_id', 'disease_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'assay_ontology_term_id', 'sex_ontology_term_id', 'development_stage_ontology_term_id', 'donor_id', 'suspension_type', 'dissection', 'fraction_mitochondrial', 'fraction_unspliced', 'cell_cycle_score', 'total_genes', 'total_UMIs', 'sample_id', 'supercluster_term', 'cluster_id', 'subcluster_id', 'cell_type_ontology_term_id', 'tissue_ontology_term_id', 'is_primary_data', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage'\n",
      "    var: 'Biotype', 'Chromosome', 'End', 'Gene', 'Start', 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype'\n",
      "    uns: 'batch_condition', 'schema_version', 'title'\n",
      "    obsm: 'X_UMAP', 'X_tSNE'\n",
      "Removed 128 genes.\n",
      "Seeing 8587 outliers (63.03% of total dataset):\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'dpt_group' as categorical\n",
      "... storing 'symbol' as categorical\n",
      "... storing 'ncbi_gene_id' as categorical\n",
      "... storing 'biotype' as categorical\n",
      "... storing 'description' as categorical\n",
      "... storing 'synonyms' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "AnnData object with n_obs √ó n_vars = 21181 √ó 19157\n",
      "    obs: 'assay_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'is_primary_data', 'organism_ontology_term_id', 'sample', 'tissue_ontology_term_id', 'disease_state', 'sex_ontology_term_id', 'genotype', 'development_stage_ontology_term_id', 'author_cell_type', 'cell_type_ontology_term_id', 'disease_ontology_term_id', 'donor_id', 'suspension_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage'\n",
      "    var: 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype'\n",
      "    uns: 'schema_version', 'title'\n",
      "    obsm: 'X_spatial'\n",
      "Removed 38 genes.\n",
      "Seeing 374 outliers (3.52% of total dataset):\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'dpt_group' as categorical\n",
      "... storing 'symbol' as categorical\n",
      "... storing 'ncbi_gene_id' as categorical\n",
      "... storing 'biotype' as categorical\n",
      "... storing 'description' as categorical\n",
      "... storing 'synonyms' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "AnnData object with n_obs √ó n_vars = 32900 √ó 21189\n",
      "    obs: 'assay_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'is_primary_data', 'organism_ontology_term_id', 'sample', 'tissue_ontology_term_id', 'disease_state', 'sex_ontology_term_id', 'genotype', 'development_stage_ontology_term_id', 'author_cell_type', 'cell_type_ontology_term_id', 'disease_ontology_term_id', 'donor_id', 'suspension_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage'\n",
      "    var: 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype'\n",
      "    uns: 'schema_version', 'title'\n",
      "    obsm: 'X_spatial'\n",
      "Removed 48 genes.\n",
      "Seeing 1110 outliers (4.61% of total dataset):\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'dpt_group' as categorical\n",
      "... storing 'symbol' as categorical\n",
      "... storing 'ncbi_gene_id' as categorical\n",
      "... storing 'biotype' as categorical\n",
      "... storing 'description' as categorical\n",
      "... storing 'synonyms' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "AnnData object with n_obs √ó n_vars = 5729 √ó 30666\n",
      "    obs: 'organism_ontology_term_id', 'tissue_ontology_term_id', 'assay_ontology_term_id', 'disease_ontology_term_id', 'cell_type_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'development_stage_ontology_term_id', 'sex_ontology_term_id', 'knockout', 'day', 'sample', 'annotation', 'is_primary_data', 'suspension_type', 'donor_id', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage'\n",
      "    var: 'gene_name', 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype'\n",
      "    uns: 'batch_condition', 'schema_version', 'title'\n",
      "    obsm: 'X_umap'\n",
      "Dataset dropped because contains too many secondary cells\n",
      "5\n",
      "AnnData object with n_obs √ó n_vars = 16375 √ó 58604\n",
      "    obs: 'assay_ontology_term_id', 'donor_id', 'anatomical_information', 'n_counts_UMIs', 'n_genes', 'cell_ontology_class', 'free_annotation', 'manually_annotated', 'compartment', 'sex_ontology_term_id', 'disease_ontology_term_id', 'is_primary_data', 'organism_ontology_term_id', 'suspension_type', 'cell_type_ontology_term_id', 'tissue_ontology_term_id', 'development_stage_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage'\n",
      "    var: 'feature_type', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std', 'ensembl_version', 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype'\n",
      "    uns: '_scvi', '_training_mode', 'assay_colors', 'cell_ontology_class_colors', 'dendrogram_cell_type_tissue', 'dendrogram_computational_compartment_assignment', 'dendrogram_consensus_prediction', 'dendrogram_tissue_cell_type', 'donor_id_colors', 'hvg', 'neighbors', 'schema_version', 'sex_colors', 'tissue_colors', 'title', 'umap'\n",
      "    obsm: 'X_pca', 'X_scvi', 'X_scvi_umap', 'X_umap'\n",
      "    obsp: 'connectivities', 'distances'\n",
      "Dataset dropped because contains too many secondary cells\n",
      "6\n",
      "AnnData object with n_obs √ó n_vars = 76592 √ó 33178\n",
      "    obs: 'nCount_RNA', 'nFeature_RNA', 'Location', 'PCW', 'Genotype', 'Pool', 'Collection.ID', 'Cluster', 'disease_ontology_term_id', 'assay_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'cell_type_ontology_term_id', 'is_primary_data', 'organism_ontology_term_id', 'donor_id', 'development_stage_ontology_term_id', 'sex_ontology_term_id', 'tissue_ontology_term_id', 'suspension_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage'\n",
      "    var: 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype'\n",
      "    uns: 'schema_version', 'title'\n",
      "    obsm: 'X_pca', 'X_umap'\n",
      "Removed 94 genes.\n",
      "Seeing 45696 outliers (59.66% of total dataset):\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'dpt_group' as categorical\n",
      "... storing 'symbol' as categorical\n",
      "... storing 'ncbi_gene_id' as categorical\n",
      "... storing 'biotype' as categorical\n",
      "... storing 'description' as categorical\n",
      "... storing 'synonyms' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "AnnData object with n_obs √ó n_vars = 3083 √ó 16443\n",
      "    obs: 'n_counts', 'n_genes', 'percent.mt', 'Adipocyte', 'Cardiomyocyte', 'Endothelial', 'Fibroblast', 'Lymphoid', 'Mast', 'Myeloid', 'Neuronal', 'Pericyte', 'Cycling.cells', 'vSMCs', 'cell_type_original', 'assay_ontology_term_id', 'cell_type_ontology_term_id', 'development_stage_ontology_term_id', 'disease_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'is_primary_data', 'organism_ontology_term_id', 'sex_ontology_term_id', 'tissue_ontology_term_id', 'donor_id', 'suspension_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage'\n",
      "    var: 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype'\n",
      "    uns: 'X_approximate_distribution', 'default_embedding', 'schema_version', 'title'\n",
      "    obsm: 'X_pca', 'X_spatial', 'X_umap'\n",
      "Removed 37 genes.\n",
      "Seeing 1481 outliers (48.04% of total dataset):\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'dpt_group' as categorical\n",
      "... storing 'symbol' as categorical\n",
      "... storing 'ncbi_gene_id' as categorical\n",
      "... storing 'biotype' as categorical\n",
      "... storing 'description' as categorical\n",
      "... storing 'synonyms' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "AnnData object with n_obs √ó n_vars = 11265 √ó 59357\n",
      "    obs: 'roi', 'organism_ontology_term_id', 'disease_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'assay_ontology_term_id', 'sex_ontology_term_id', 'development_stage_ontology_term_id', 'donor_id', 'suspension_type', 'dissection', 'fraction_mitochondrial', 'fraction_unspliced', 'cell_cycle_score', 'total_genes', 'total_UMIs', 'sample_id', 'supercluster_term', 'cluster_id', 'subcluster_id', 'cell_type_ontology_term_id', 'tissue_ontology_term_id', 'is_primary_data', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage'\n",
      "    var: 'Biotype', 'Chromosome', 'End', 'Gene', 'Start', 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype'\n",
      "    uns: 'batch_condition', 'schema_version', 'title'\n",
      "    obsm: 'X_UMAP', 'X_tSNE'\n",
      "Removed 128 genes.\n",
      "Seeing 6290 outliers (55.84% of total dataset):\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'dpt_group' as categorical\n",
      "... storing 'symbol' as categorical\n",
      "... storing 'ncbi_gene_id' as categorical\n",
      "... storing 'biotype' as categorical\n",
      "... storing 'description' as categorical\n",
      "... storing 'synonyms' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    }
   ],
   "source": [
    "preprocessed_dataset = do_preprocess(mydataset, start_at=11, description=DESCRIPTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we have processed that many files\n",
    "len(ln.File.filter(version='2', description=DESCRIPTION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can load a preprocessed anndata like this\n",
    "adata = ln.File.filter(version='2', description=DESCRIPTION)[23].backed()\n",
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'files'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ml4ig1/Documents code/scPRINT/notebooks/assessments/finalize_data_loader copy.ipynb Cell 27\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bperso/home/ml4ig1/Documents%20code/scPRINT/notebooks/assessments/finalize_data_loader%20copy.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m dataset \u001b[39m=\u001b[39m ln\u001b[39m.\u001b[39mDataset(ln\u001b[39m.\u001b[39mFile\u001b[39m.\u001b[39mfilter(version\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m2\u001b[39m\u001b[39m'\u001b[39m, description\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpreprocessed by scprint\u001b[39m\u001b[39m'\u001b[39m), name\u001b[39m=\u001b[39mname, description\u001b[39m=\u001b[39mdescription)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bperso/home/ml4ig1/Documents%20code/scPRINT/notebooks/assessments/finalize_data_loader%20copy.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m dataset\u001b[39m.\u001b[39msave()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bperso/home/ml4ig1/Documents%20code/scPRINT/notebooks/assessments/finalize_data_loader%20copy.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m dataset\u001b[39m.\u001b[39;49mfiles\u001b[39m.\u001b[39mcount()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'files'"
     ]
    }
   ],
   "source": [
    "# I need to remake the dataset as it failed for some files and I had to restart at position 11 (As you can see in the preprocess() function)\n",
    "name=\"preprocessed dataset\"\n",
    "description=\"preprocessed dataset using scprint\"\n",
    "dataset = ln.Dataset(ln.File.filter(version='2', description=DESCRIPTION), name=name, description=description)\n",
    "dataset.save()\n",
    "dataset.files.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scprint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
